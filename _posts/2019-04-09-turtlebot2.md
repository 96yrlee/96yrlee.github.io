---
layout: post
title: "Turtlebot2 Coding Challenges"
sub_title: "a"
categories:
  - Projects
tags:
- Coding
- Robotics
last_modified_at: 2019-04-09 
---


## Introduction 
This was for the UofT course MIE443: Mechatronics Systems: Integration and Design. Each group was assigned a Turtlebot2 to program control systems and complete three challenges:

1. [Mapping an enclosure](#1)
2. [Travel to and catalogue 5 objects before returning "home"](#2)
    1. [A video of a succesful test run](#2a)
3. [Follow a user and react to the enviroment with emotions](#3)

I worked with Christine, Dave and Jack. Together, we all developed the strategies and control system architecture, wrote and tested the code on the turtlebot2, and wrote reports detailing our methodology and results.

<p>&nbsp;</p> 

## Basic Infomation

![img2](https://www.turtlebot.com/assets/images/turtlebot_2_lg.png){:width="225"} | A turtlebot is an open-sourced personal robot that runs on ROS. It comprises of a Kabuki base with motorized wheels and bumer sensor, a kinect sensor and some additional strcuture.

<p>&nbsp;</p> 

## Mapping an Enclosure: Object Avoidance and Autonomous Mapping <a name="1"></a>
In this contest, I collaborated to tune the laser scan code and code the exploration strategy. 

The goal was to autonomously explore an unknown enclosure while using the built-in mapping capabilities. 

| The objectives, in descending priorty, were to: | The constraints were:|
| -------- | ----------- |
| - Cover the entire area. <br> - Accurately map the area<br>- Reduce the time spent, with a max limit of 8 minutes.<br>- Avoid using the contact sensors: they were included to protect the robot, but were to be avoided. | - that the map must be formed from sensory data by the Kinect.<br>- that the robot must be fully automonous, no human intervention.<br>- a speed limit of 0.25m/s, and of 0.1m/s  near obstacles.<br>- that vel_pub was the only allowed publisher, eliminating pre-packaged exploration and object avoidance code. |


**Basic explanation on how the sensors, code and motors work together**
 
{::options parse_block_html="true" /} 
 
<details>
  <summary markdown="span">Click to see the Control Architecture Flowchart!</summary>
  
  ![img2](/images/projects/turtlebot2/flowchart_controller_architecture.PNG "Contest 1 Flowchart")
  
  Diagram credit to Christine for drawing it 
    
</details>

{::options parse_block_html="false" /}

**Basic explanation on how we got distance data**

The kinect is not an actual simple laser sensor. However, it can be used as such and the process for this was pre-packaged into a laser sensor array with over 600 elements. We discretized it into 10 by average the points for easier use and coding.

With this, we now had information on how close an object was to the front of the Turtlebot2 at each angle - This formed the basis of our object avoidance algorithm and thus our exploration code.
  
{::options parse_block_html="true" /} 

<details>
  <summary markdown="span">Click to see the kinect sensor discretation process!</summary>

  ![img2](/images/projects/turtlebot2/discretation_process_laserCallback.PNG "How the Laser Works")
  
  Image credit to the course for providing it 
    
</details>

{::options parse_block_html="false" /}

<p>&nbsp;</p> 

## Find and Catalogue Objects: Path Planning and Image Identification <a name="2"></a>
In this contest, I was responsible for creating the path planning functions, adjusting the given coordinates of the boxes and sorting all the data so my group could use it. I also collaborated on testing the robot for all purposes.

The goal was to autonomously travel to boxes with given coordinates, catalogue the image on them correct, return to the starting position and then print a text file stating which box had which image. The area had no objects other than the 5 boxes, there were 3 images and 1 blank sheet. Also, one of the images would repeat. We were given a map and coordinates of each box, and were given the 3 images to compare with.

| The objectives, in descending priorty, were to: | The constraints were:|
| -------- | ----------- |
| - Catalogue the images accurately. <br> - Minimize the time spent, with a max limit of 5 minutes. | - that the map must be formed from sensory data by the Kinect.<br>- that the robot must be fully automonous.<br>- a speed limit of 0.25m/s, and of 0.1m/s  near obstacles.<br>- that vel_pub, move_base and the SURF were the only pre-packaged code. |

### Here's a video showing a successful testrun <a name="2a"></a>

<figure class="video_container">
  <video controls="true" allowfullscreen="true" height="400"> 
    <source src="/images/projects/turtlebot2/successRun.mp4" type="video/mp4">
  </video>
</figure>

Here the Turtlebot2 traveled to each box facing the correct side, correctly identified each image, and returned to its starting position.

**Here's the code for my coordinate tuning and path planning functions**

{::options parse_block_html="true" /} 
<details>
  <summary markdown="span">Click to expand!</summary>
    
  ```
    void tuning() {
        // All box locations need to be tuned, because the bot can't be where the box is exactly
        double xShift = 0.6, yShift = 0.6, phiTmp = 0;

        for(int i=1; i<=5; ++i){
          phiTmp = tCoord[i][2];

          //edge cases first
          if(phiTmp == 0){
              tCoord[i][0] += xShift;
              continue;
          }
          else if(phiTmp == pi || phiTmp == -pi){
              tCoord[i][0] -= xShift;
              continue;
          }
          else if(phiTmp == pi/2){
              tCoord[i][1] += yShift;
              continue;
          }
          else if(phiTmp == -pi/2){
              tCoord[i][1] -= yShift;
              continue;
          }

          //adjust x and y coords
          tCoord[i][1] += yShift*sin(phiTmp); tCoord[i][0] += xShift*cos(phiTmp);

          // orientation needs to flip 180degs, MUST BE AFTER AFTER EVERYTHING ELSE since they rely on phi
          if(tCoord[i][2] == 0){
              tCoord[i][2] = pi;
          }
          else if(tCoord[i][2] > 0){
              tCoord[i][2] -= pi;
          }
          else if(tCoord[i][2] < 0){
              tCoord[i][2] += pi;
          }
        } //end for loop 
      } //end of tuning()

      void TSP() {
        //brute force path finding
        double xd=0, yd=0, pathLength=0, shortest=9999;
        double path[5] ={}; // this is to hold the order for comparison simplicity

        int counter =0; // THIS IS ONLY FOR TESTING IF IT WORKS
        int num =0; // testing, to save which path generated is shortest from counter

        for(int i=5; i>0; --i){
          disBwGoals[i][i] = 0;
          for(int j=i-1; j>=0; --j){
              xd = tCoord[i][0]-tCoord[j][0]; yd = tCoord[i][1]-tCoord[j][1];
              disBwGoals[i][j] = sqrt(xd*xd + yd*yd); disBwGoals[j][i] = sqrt(xd*xd + yd*yd);
          }
        }

        for(int i=1; i<=5; ++i){
          for(int j=1; j<=5; ++j){
            if(j==i) { continue; }
            for(int k=1; k<=5; ++k){
              if(k==j || k==i) { continue; }
              for(int m=1; m<=5; ++m){
                if(m==j || m==i || m==k) { continue; }
                for(int n=1; n<=5; ++n){
                  if(n==j || n==i || n==k || n==m) { continue; }
                  pathLength = disBwGoals[0][i] + disBwGoals[i][j] + disBwGoals[j][k] + disBwGoals[k][m] + disBwGoals[m][n] + disBwGoals[n][0];
                  ++counter; //for testing if finds shortest

                  if(pathLength < shortest){
                    shortest = pathLength;
                    num = counter; //TESTING VAR
                    //save the path order for later, aka the coord row #
                    path[0] = i; path[1] = j; path[2] = k; path[3] = m; path[4] = n;
                  }
                  continue; // this is here to not waste time, since there is only one option
        } } } } }

        // fill adjustedPath
        int tmp = 0; // holds path's saved coord row#

        // HOME is always first and last, so just copy it over first
        for(int i=0; i<3; ++i){
            adjustedPath[0][i] = tCoord[0][i];
        }
        adjustedPath[0][3] = -1; // HOME doesn't exist in coord, so make it (-) just in case

        for(int i=1; i<6; ++i){
            tmp = path[i-1];
            for(int k=0; k<3;++k){
                    adjustedPath[i][k] = tCoord[tmp][k];
            }
            adjustedPath[i][3] = tmp;
        }
      } //end of TSP()
  ```
  
</details>
{::options parse_block_html="false" /}

<p>&nbsp;</p> 

## Following a Person and Reacting: A Companionbot <a name="3"></a>
In this contest, I was responsible for creating a function that would recognizably emote as rage and ensuring the machine state triggered and transistioned out correctedly.  I also collaborated on testing the robot for all purposes.

<p>&nbsp;</p> 
<p>&nbsp;</p> 

## Notes
A fair amount of the writing was summarized and all the diagrams were pulled from our reports, credit to my teammates

Also, I consider this page to be incomplete, but sufficient. More details and edits to be added in time.









